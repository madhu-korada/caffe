name: "CIFAR10_full_train"
# input image must be in CIFAR-10 format
# Data layer

layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/madhu/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/madhu/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
# convolution layer - Conv2D(32, (3, 3), padding='same')
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32       # 32 filters
    pad: 1               # pad 1 pixel each side (same)
    kernel_size: 3       # each 3x3  
    stride: 1            # step 1 pixel between each filter
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
# ReLU layer - Activation('relu')
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
# Conv2D(32, (3, 3))
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32       # 32 filters
    pad: 0               # NO padding (valid)
    kernel_size: 3       # each 3x3  
    stride: 1            # step 1 pixel between each filter
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
# ReLU layer - Activation('relu')
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
# MaxPooling2D(pool_size=(2, 2))
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
# Dropout(0.25)
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "pool1"
  top: "pool1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
# Conv2D(64, (3, 3), padding='same')
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool1"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64       # 64 filters
    pad: 1               # pad 1 pixel each side (same)
    kernel_size: 3       # each 3x3  
    stride: 1            # step 1 pixel between each filter 
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
# Activation('relu')
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
# Conv2D(64, (3, 3))
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64       # 64 filters
    pad: 0               # NO padding (valid)
    kernel_size: 3       # each 3x3  
    stride: 1            # step 1 pixel between each filter 
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
# Activation('relu')
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
# MaxPooling2D(pool_size=(2, 2))
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv4"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
# Dropout(0.25)
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "pool2"
  top: "pool2"
  dropout_param {
    dropout_ratio: 0.25
  }
}
# Flatten()
layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool2"
  top: "flatten"
}
# Dense(512)
layer {
  name: "dense1"
  type: "InnerProduct"
  bottom: "flatten"
  top: "dense1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
# Activation('relu')
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "dense1"
  top: "dense1"
}
# Dropout(0.5)
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "dense1"
  top: "dense1"
  dropout_param {
    dropout_ratio: 0.25
  }
}
# Dense(num_classes)
layer {
  name: "dense2"
  type: "InnerProduct"
  bottom: "dense1"
  top: "dense2"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
# Accuracy testing phase
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "dense2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
# Activation('softmax')
layer {
  name: "softmax"
  type: "SoftmaxWithLoss"
  bottom: "dense2"
  bottom: "label"
  top: "loss"
}
